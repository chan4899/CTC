----------------- Options ---------------
             aspect_ratio: 1                             
               batch_size: 64                            	[default: 1]
          checkpoints_dir: /home1/btp/pkb_btp_1/checkpoints
                crop_size: 128                           	[default: 256]
                 dataroot: /home1/btp/pkb_btp_1/data/voc_data/	[default: None]
             dataset_mode: colorization                  
                direction: AtoB                          
          display_winsize: 512                           
                    epoch: latest                        
                     eval: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 1                             
                  isTrain: False                         	[default: None]
                load_iter: 0                             	[default: 0]
                load_size: 128                           	[default: 512]
         max_dataset_size: inf                           
                    model: colorization                  
               n_layers_D: 3                             
                     name: pascal_voc_04                 	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_128                      	[default: unet_256]
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                     norm: batch                         
                 num_test: 10000                         
              num_threads: 4                             
                output_nc: 2                             
                    phase: test                          
               preprocess: resize_and_crop               	[default: scale_width]
              results_dir: /home1/btp/pkb_btp_1/results/ 
           serial_batches: False                         
                   suffix:                               
                 use_sa_D: True                          	[default: False]
                 use_sa_G: True                          	[default: False]
                  verbose: False                         
----------------- End -------------------
dataset [ColorizationDataset] was created
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Self attention initialized with 256 channels.
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
----------------- Options ---------------
             aspect_ratio: 1                             
               batch_size: 64                            	[default: 1]
          checkpoints_dir: /home1/btp/pkb_btp_1/checkpoints
                crop_size: 128                           	[default: 256]
                 dataroot: /home1/btp/pkb_btp_1/data/voc_data/	[default: None]
             dataset_mode: colorization                  
                direction: AtoB                          
          display_winsize: 512                           
                    epoch: latest                        
                     eval: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 1                             
                  isTrain: False                         	[default: None]
                load_iter: 0                             	[default: 0]
                load_size: 128                           	[default: 512]
         max_dataset_size: inf                           
                    model: colorization                  
               n_layers_D: 3                             
                     name: pascal_voc_04                 	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_128                      	[default: unet_256]
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                     norm: batch                         
                 num_test: 10000                         
              num_threads: 4                             
                output_nc: 2                             
                    phase: test                          
               preprocess: resize_and_crop               	[default: scale_width]
              results_dir: /home1/btp/pkb_btp_1/results/ 
           serial_batches: False                         
                   suffix:                               
                 use_sa_D: True                          	[default: False]
                 use_sa_G: True                          	[default: False]
                  verbose: False                         
----------------- End -------------------
dataset [ColorizationDataset] was created
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Self attention initialized with 256 channels.
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
Spectral layer initialized
initialize network with normal
model [ColorizationModel] was created
loading the model from /home1/btp/pkb_btp_1/checkpoints/pascal_voc_04/latest_net_G.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 41.978 M
-----------------------------------------------
creating web directory /home1/btp/pkb_btp_1/results/pascal_voc_04/test_latest
processing (0000)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2007_000491.jpg']
processing (0005)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_000365.jpg']
processing (0010)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_001466.jpg']
processing (0015)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_002647.jpg']
processing (0020)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_003467.jpg']
processing (0025)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_003951.jpg']
processing (0030)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_004702.jpg']
processing (0035)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_005404.jpg']
processing (0040)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_006082.jpg']
processing (0045)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_007438.jpg']
processing (0050)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2008_007585.jpg']
processing (0055)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2009_000282.jpg']
processing (0060)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2009_001470.jpg']
processing (0065)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2009_002086.jpg']
processing (0070)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2009_002995.jpg']
processing (0075)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2009_004264.jpg']
processing (0080)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2009_005300.jpg']
processing (0085)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_000661.jpg']
processing (0090)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_001331.jpg']
processing (0095)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_002479.jpg']
processing (0100)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_003107.jpg']
processing (0105)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_003653.jpg']
processing (0110)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_004537.jpg']
processing (0115)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_005496.jpg']
processing (0120)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_006106.jpg']
processing (0125)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_006518.jpg']
processing (0130)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2010_006964.jpg']
processing (0135)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2011_000507.jpg']
processing (0140)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2011_001375.jpg']
processing (0145)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2011_002173.jpg']
processing (0150)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2011_003216.jpg']
processing (0155)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2011_003977.jpg']
processing (0160)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2011_004618.jpg']
processing (0165)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2011_005613.jpg']
processing (0170)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2011_006820.jpg']
processing (0175)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2012_001380.jpg']
processing (0180)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2012_001904.jpg']
processing (0185)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2012_002494.jpg']
processing (0190)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2012_003197.jpg']
processing (0195)-th image... ['/home1/btp/pkb_btp_1/data/voc_data/test/2012_003798.jpg']
[tensor(0.8530, dtype=torch.float64), tensor(0.9021, dtype=torch.float64), tensor(0.8872, dtype=torch.float64), tensor(0.8557, dtype=torch.float64), tensor(0.8449, dtype=torch.float64), tensor(0.8785, dtype=torch.float64), tensor(0.8642, dtype=torch.float64), tensor(0.8833, dtype=torch.float64), tensor(0.8755, dtype=torch.float64), tensor(0.8519, dtype=torch.float64), tensor(0.8966, dtype=torch.float64), tensor(0.8042, dtype=torch.float64), tensor(0.8029, dtype=torch.float64), tensor(0.7919, dtype=torch.float64), tensor(0.8767, dtype=torch.float64), tensor(0.9456, dtype=torch.float64), tensor(0.8394, dtype=torch.float64), tensor(0.8706, dtype=torch.float64), tensor(0.8641, dtype=torch.float64), tensor(0.8887, dtype=torch.float64), tensor(0.8619, dtype=torch.float64), tensor(0.8582, dtype=torch.float64), tensor(0.8772, dtype=torch.float64), tensor(0.6685, dtype=torch.float64), tensor(0.8671, dtype=torch.float64), tensor(0.8979, dtype=torch.float64), tensor(0.8639, dtype=torch.float64), tensor(0.6777, dtype=torch.float64), tensor(0.8956, dtype=torch.float64), tensor(0.7703, dtype=torch.float64), tensor(0.7781, dtype=torch.float64), tensor(0.6807, dtype=torch.float64), tensor(0.8643, dtype=torch.float64), tensor(0.8745, dtype=torch.float64), tensor(0.8535, dtype=torch.float64), tensor(0.7667, dtype=torch.float64), tensor(0.8670, dtype=torch.float64), tensor(0.8915, dtype=torch.float64), tensor(0.8822, dtype=torch.float64), tensor(0.8624, dtype=torch.float64), tensor(0.8324, dtype=torch.float64), tensor(0.8723, dtype=torch.float64), tensor(0.8357, dtype=torch.float64), tensor(0.8645, dtype=torch.float64), tensor(0.7925, dtype=torch.float64), tensor(0.8103, dtype=torch.float64), tensor(0.8435, dtype=torch.float64), tensor(0.9106, dtype=torch.float64), tensor(0.7954, dtype=torch.float64), tensor(0.8754, dtype=torch.float64), tensor(0.7904, dtype=torch.float64), tensor(0.7672, dtype=torch.float64), tensor(0.8087, dtype=torch.float64), tensor(0.8785, dtype=torch.float64), tensor(0.8599, dtype=torch.float64), tensor(0.9240, dtype=torch.float64), tensor(0.8645, dtype=torch.float64), tensor(0.8582, dtype=torch.float64), tensor(0.5363, dtype=torch.float64), tensor(0.7982, dtype=torch.float64), tensor(0.8298, dtype=torch.float64), tensor(0.8611, dtype=torch.float64), tensor(0.9095, dtype=torch.float64), tensor(0.6056, dtype=torch.float64), tensor(0.8543, dtype=torch.float64), tensor(0.8820, dtype=torch.float64), tensor(0.8563, dtype=torch.float64), tensor(0.8318, dtype=torch.float64), tensor(0.9120, dtype=torch.float64), tensor(0.7516, dtype=torch.float64), tensor(0.7728, dtype=torch.float64), tensor(0.9034, dtype=torch.float64), tensor(0.8931, dtype=torch.float64), tensor(0.8729, dtype=torch.float64), tensor(0.8909, dtype=torch.float64), tensor(0.8765, dtype=torch.float64), tensor(0.7611, dtype=torch.float64), tensor(0.8946, dtype=torch.float64), tensor(0.8737, dtype=torch.float64), tensor(0.8174, dtype=torch.float64), tensor(0.8763, dtype=torch.float64), tensor(0.8768, dtype=torch.float64), tensor(0.7418, dtype=torch.float64), tensor(0.8769, dtype=torch.float64), tensor(0.8439, dtype=torch.float64), tensor(0.8785, dtype=torch.float64), tensor(0.9199, dtype=torch.float64), tensor(0.8557, dtype=torch.float64), tensor(0.8871, dtype=torch.float64), tensor(0.8531, dtype=torch.float64), tensor(0.8884, dtype=torch.float64), tensor(0.8918, dtype=torch.float64), tensor(0.8960, dtype=torch.float64), tensor(0.8252, dtype=torch.float64), tensor(0.8754, dtype=torch.float64), tensor(0.7751, dtype=torch.float64), tensor(0.8801, dtype=torch.float64), tensor(0.8708, dtype=torch.float64), tensor(0.8464, dtype=torch.float64), tensor(0.8482, dtype=torch.float64), tensor(0.9058, dtype=torch.float64), tensor(0.6672, dtype=torch.float64), tensor(0.9011, dtype=torch.float64), tensor(0.9107, dtype=torch.float64), tensor(0.8540, dtype=torch.float64), tensor(0.8116, dtype=torch.float64), tensor(0.7849, dtype=torch.float64), tensor(0.9137, dtype=torch.float64), tensor(0.8539, dtype=torch.float64), tensor(0.8527, dtype=torch.float64), tensor(0.8712, dtype=torch.float64), tensor(0.9127, dtype=torch.float64), tensor(0.8243, dtype=torch.float64), tensor(0.8688, dtype=torch.float64), tensor(0.9266, dtype=torch.float64), tensor(0.8587, dtype=torch.float64), tensor(0.8778, dtype=torch.float64), tensor(0.8930, dtype=torch.float64), tensor(0.8071, dtype=torch.float64), tensor(0.8597, dtype=torch.float64), tensor(0.8305, dtype=torch.float64), tensor(0.8522, dtype=torch.float64), tensor(0.8866, dtype=torch.float64), tensor(0.8612, dtype=torch.float64), tensor(0.8772, dtype=torch.float64), tensor(0.8507, dtype=torch.float64), tensor(0.6583, dtype=torch.float64), tensor(0.8611, dtype=torch.float64), tensor(0.8981, dtype=torch.float64), tensor(0.8457, dtype=torch.float64), tensor(0.8700, dtype=torch.float64), tensor(0.8664, dtype=torch.float64), tensor(0.9016, dtype=torch.float64), tensor(0.8479, dtype=torch.float64), tensor(0.8322, dtype=torch.float64), tensor(0.8547, dtype=torch.float64), tensor(0.8676, dtype=torch.float64), tensor(0.8818, dtype=torch.float64), tensor(0.8681, dtype=torch.float64), tensor(0.5817, dtype=torch.float64), tensor(0.8604, dtype=torch.float64), tensor(0.8796, dtype=torch.float64), tensor(0.8518, dtype=torch.float64), tensor(0.9147, dtype=torch.float64), tensor(0.9124, dtype=torch.float64), tensor(0.8436, dtype=torch.float64), tensor(0.7748, dtype=torch.float64), tensor(0.8851, dtype=torch.float64), tensor(0.8987, dtype=torch.float64), tensor(0.8778, dtype=torch.float64), tensor(0.8512, dtype=torch.float64), tensor(0.8987, dtype=torch.float64), tensor(0.9093, dtype=torch.float64), tensor(0.8621, dtype=torch.float64), tensor(0.8726, dtype=torch.float64), tensor(0.8542, dtype=torch.float64), tensor(0.9235, dtype=torch.float64), tensor(0.8321, dtype=torch.float64), tensor(0.8728, dtype=torch.float64), tensor(0.7633, dtype=torch.float64), tensor(0.8012, dtype=torch.float64), tensor(0.8720, dtype=torch.float64), tensor(0.8789, dtype=torch.float64), tensor(0.8728, dtype=torch.float64), tensor(0.8581, dtype=torch.float64), tensor(0.8555, dtype=torch.float64), tensor(0.8425, dtype=torch.float64), tensor(0.8872, dtype=torch.float64), tensor(0.9094, dtype=torch.float64), tensor(0.9085, dtype=torch.float64), tensor(0.8092, dtype=torch.float64), tensor(0.7015, dtype=torch.float64), tensor(0.8538, dtype=torch.float64), tensor(0.8441, dtype=torch.float64), tensor(0.9078, dtype=torch.float64), tensor(0.8628, dtype=torch.float64), tensor(0.8526, dtype=torch.float64), tensor(0.7866, dtype=torch.float64), tensor(0.8784, dtype=torch.float64), tensor(0.8663, dtype=torch.float64), tensor(0.8900, dtype=torch.float64), tensor(0.8612, dtype=torch.float64), tensor(0.8131, dtype=torch.float64), tensor(0.8758, dtype=torch.float64), tensor(0.8042, dtype=torch.float64), tensor(0.8186, dtype=torch.float64), tensor(0.8374, dtype=torch.float64), tensor(0.8778, dtype=torch.float64), tensor(0.8784, dtype=torch.float64), tensor(0.8721, dtype=torch.float64), tensor(0.8359, dtype=torch.float64), tensor(0.6153, dtype=torch.float64), tensor(0.8797, dtype=torch.float64), tensor(0.8191, dtype=torch.float64), tensor(0.8642, dtype=torch.float64), tensor(0.8650, dtype=torch.float64), tensor(0.8721, dtype=torch.float64), tensor(0.8943, dtype=torch.float64), tensor(0.8417, dtype=torch.float64), tensor(0.8151, dtype=torch.float64)]
tensor(169.5802, dtype=torch.float64)
